# Amazon Multi-Page Scraper - Google Colab

!pip install requests beautifulsoup4 pandas --quiet

import requests
from bs4 import BeautifulSoup
import pandas as pd
from IPython.display import display, HTML

HEADERS = {
    "User-Agent": "Mozilla/5.0 (Windows NT 10.0; Win64; x64) "
                  "AppleWebKit/537.36 (KHTML, like Gecko) "
                  "Chrome/114.0.0.0 Safari/537.36",
    "Accept-Language": "en-US,en;q=0.9",
}

def scrape_amazon(query, pages=3, results_per_page=12):
    all_rows = []

    for page in range(1, pages + 1):
        url = f"https://www.amazon.in/s?k={query.replace(' ','+')}&page={page}"
        resp = requests.get(url, headers=HEADERS, timeout=15)

        soup = BeautifulSoup(resp.content, "html.parser")
        results = soup.find_all("div", {"data-component-type": "s-search-result"})

        for r in results[:results_per_page]:
            h2 = r.find("h2")
            if not h2:
                continue
            title = h2.text.strip()
            a_tag = h2.find("a")
            href = a_tag["href"] if a_tag else ""
            link = "https://www.amazon.in" + href if href else ""
            
            price_whole = r.find("span", class_="a-price-whole")
            price_frac = r.find("span", class_="a-price-fraction")
            price = ""
            if price_whole:
                price = price_whole.text.strip() + (("." + price_frac.text.strip()) if price_frac else "")
            
            rating_tag = r.find("span", class_="a-icon-alt")
            rating = rating_tag.text.strip() if rating_tag else ""
            
            review_tag = r.select_one("span.a-size-base")
            reviews = review_tag.text.strip() if review_tag else ""
            
            all_rows.append({
                "Title": title,
                "Price": price,
                "Rating": rating,
                "Reviews": reviews,
                "Link": link
            })
    
    return pd.DataFrame(all_rows)

# --- User Input ---
query = input("Enter Amazon search query: ")
pages = int(input("Number of pages to scrape (1-5 recommended): "))

df = scrape_amazon(query, pages=pages)
print(f"\nFetched {len(df)} results from {pages} pages.")

# Display table with clickable links
df_display = df.copy()
df_display['Link'] = df_display['Link'].apply(lambda x: f'<a href="{x}" target="_blank">View</a>')
display(HTML(df_display.to_html(escape=False, index=False)))

# Optionally, save to CSV
csv_file = f"amazon_{query.replace(' ','_')}.csv"
df.to_csv(csv_file, index=False)
print(f"CSV saved as: {csv_file}")
